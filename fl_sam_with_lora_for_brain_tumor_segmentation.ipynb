{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdcf2Zrpn/nTA5yWgbMS2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-sai-reddy/fl-sam-lora-for-brain-tumor-segmentation/blob/main/fl_sam_with_lora_for_brain_tumor_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsKypNFclQHn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import SamModel, SamProcessor\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Download the brain tumor dataset\n",
        "print(\"Downloading Brain Tumor Dataset...\")\n",
        "path = kagglehub.dataset_download(\"indk214/brain-tumor-dataset-segmentation-and-classification\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "class RealBrainTumorDataset(Dataset):\n",
        "    def __init__(self, data_dir, processor=None, client_id=0, num_clients=3, samples_per_client=50):\n",
        "        self.data_dir = data_dir\n",
        "        self.processor = processor\n",
        "        self.client_id = client_id\n",
        "        self.num_clients = num_clients\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "\n",
        "        print(f\"üîç Loading REAL brain tumor data from: {data_dir}\")\n",
        "\n",
        "        # Load from the  Segmentation folders\n",
        "        if not self._load_from_segmentation_folders(data_dir, client_id, num_clients, samples_per_client):\n",
        "            raise Exception(\"‚ùå No valid image-mask pairs found in Segmentation folders\")\n",
        "\n",
        "    def _load_from_segmentation_folders(self, data_dir, client_id, num_clients, samples_per_client):\n",
        "        \"\"\"Load data from DATASET/Segmentation/ tumor type folders\"\"\"\n",
        "        segmentation_base = os.path.join(data_dir, \"DATASET\", \"Segmentation\")\n",
        "\n",
        "        if not os.path.exists(segmentation_base):\n",
        "            print(f\"‚ùå Segmentation base not found: {segmentation_base}\")\n",
        "            return False\n",
        "\n",
        "        print(\"‚úÖ Found Segmentation folders\")\n",
        "\n",
        "        # Tumor types in this dataset\n",
        "        tumor_types = [\"Pituitary tumor\", \"Meningioma\", \"Glioma\"]\n",
        "        all_pairs = []\n",
        "\n",
        "        for tumor_type in tumor_types:\n",
        "            tumor_path = os.path.join(segmentation_base, tumor_type)\n",
        "            if os.path.exists(tumor_path):\n",
        "                print(f\"üìÇ Processing {tumor_type}...\")\n",
        "\n",
        "                # Get all files in this tumor folder\n",
        "                tumor_files = [f for f in os.listdir(tumor_path) if f.endswith('.png')]\n",
        "                image_files = [f for f in tumor_files if 'mask' not in f]\n",
        "                mask_files = [f for f in tumor_files if 'mask' in f]\n",
        "\n",
        "                print(f\"   Found {len(image_files)} images, {len(mask_files)} masks\")\n",
        "\n",
        "                # Create pairs for this tumor type\n",
        "                for img_file in image_files:\n",
        "                    mask_file = img_file.replace('.png', '_mask.png')\n",
        "                    if mask_file in mask_files:\n",
        "                        img_path = os.path.join(tumor_path, img_file)\n",
        "                        mask_path = os.path.join(tumor_path, mask_file)\n",
        "                        all_pairs.append((img_path, mask_path))\n",
        "\n",
        "        print(f\"üìä Total image-mask pairs found: {len(all_pairs)}\")\n",
        "\n",
        "        if not all_pairs:\n",
        "            return False\n",
        "\n",
        "        print(\"\\nüîç Analyzing mask diversity:\")\n",
        "        unique_patterns = set()\n",
        "        for img_path, mask_path in all_pairs[:10]:  # Check first 10\n",
        "            try:\n",
        "                mask = Image.open(mask_path).convert('L')\n",
        "                mask_array = np.array(mask)\n",
        "                unique_vals = tuple(np.unique(mask_array))\n",
        "                unique_patterns.add(unique_vals)\n",
        "                print(f\"  {os.path.basename(mask_path)}: values={unique_vals}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f\"üéØ Found {len(unique_patterns)} unique mask patterns\")\n",
        "\n",
        "        # Split pairs among clients\n",
        "        pairs_per_client = max(1, len(all_pairs) // num_clients)\n",
        "        start_idx = client_id * pairs_per_client\n",
        "        end_idx = start_idx + pairs_per_client if client_id < num_clients - 1 else len(all_pairs)\n",
        "        client_pairs = all_pairs[start_idx:end_idx][:samples_per_client]\n",
        "\n",
        "        print(f\"üë§ Client {client_id} got {len(client_pairs)} pairs\")\n",
        "\n",
        "        # Load valid pairs\n",
        "        valid_pairs = 0\n",
        "        for img_path, mask_path in client_pairs:\n",
        "            if os.path.exists(img_path) and os.path.exists(mask_path):\n",
        "                self.images.append(img_path)\n",
        "                self.masks.append(mask_path)\n",
        "                valid_pairs += 1\n",
        "\n",
        "        print(f\"‚úÖ Successfully loaded {valid_pairs} REAL brain tumor samples\")\n",
        "        return valid_pairs > 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.images[idx]\n",
        "            mask_path = self.masks[idx]\n",
        "\n",
        "            # Load real image and mask\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            mask = Image.open(mask_path).convert('L')\n",
        "\n",
        "            # Resize to standard size (maintains aspect ratio better)\n",
        "            target_size = (512, 512)\n",
        "            image = image.resize(target_size, Image.LANCZOS)\n",
        "            mask = mask.resize(target_size, Image.NEAREST)\n",
        "\n",
        "            mask_array = np.array(mask)\n",
        "\n",
        "            # Handle different mask value patterns\n",
        "            unique_vals = np.unique(mask_array)\n",
        "\n",
        "            if np.array_equal(unique_vals, [0, 255]):\n",
        "                # Binary mask with 0 and 255\n",
        "                binary_mask = (mask_array == 255).astype(np.uint8)\n",
        "            elif np.array_equal(unique_vals, [3, 255]):\n",
        "                # Some masks have [3, 255] values\n",
        "                binary_mask = (mask_array == 255).astype(np.uint8)\n",
        "            else:\n",
        "                # Generic threshold\n",
        "                binary_mask = (mask_array > 127).astype(np.uint8)\n",
        "\n",
        "            # Debug first sample\n",
        "            if idx == 0:\n",
        "                print(f\"\\nüîç First sample debug:\")\n",
        "                print(f\"   Image: {os.path.basename(image_path)}\")\n",
        "                print(f\"   Mask: {os.path.basename(mask_path)}\")\n",
        "                print(f\"   Original mask values: {unique_vals}\")\n",
        "                print(f\"   Binary mask non-zero: {np.count_nonzero(binary_mask)}\")\n",
        "                print(f\"   Image size: {image.size}, Mask size: {mask.size}\")\n",
        "\n",
        "            if self.processor:\n",
        "                # Get bounding box from mask\n",
        "                y_indices, x_indices = np.where(binary_mask > 0)\n",
        "                if len(x_indices) > 0 and len(y_indices) > 0:\n",
        "                    box = [[x_indices.min(), y_indices.min(), x_indices.max(), y_indices.max()]]\n",
        "                else:\n",
        "                    h, w = binary_mask.shape\n",
        "                    box = [[w//4, h//4, 3*w//4, 3*h//4]]\n",
        "\n",
        "                inputs = self.processor(\n",
        "                    image,\n",
        "                    input_boxes=[box],\n",
        "                    return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                for key in inputs:\n",
        "                    if torch.is_tensor(inputs[key]):\n",
        "                        inputs[key] = inputs[key].squeeze(0)\n",
        "\n",
        "                inputs[\"ground_truth_mask\"] = torch.tensor(binary_mask).unsqueeze(0)\n",
        "                return inputs\n",
        "\n",
        "            return {\n",
        "                'pixel_values': torch.tensor(np.array(image)).permute(2, 0, 1).float(),\n",
        "                'input_boxes': torch.tensor([[100, 100, 200, 200]]),\n",
        "                'ground_truth_mask': torch.tensor(binary_mask).unsqueeze(0)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading real sample {idx}: {e}\")\n",
        "            print(f\"   Image: {self.images[idx]}\")\n",
        "            print(f\"   Mask: {self.masks[idx]}\")\n",
        "            raise\n",
        "\n",
        "def create_sam_lora():\n",
        "    print(\"Loading SAM model with LoRA...\")\n",
        "    model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n",
        "    processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    print(\"Trainable parameters:\")\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, processor\n",
        "\n",
        "class FedProxTrainer:\n",
        "    def __init__(self, model, mu=0.01):\n",
        "        self.global_model = model\n",
        "        self.mu = mu\n",
        "        self.global_params = None\n",
        "        self._update_global_params()\n",
        "\n",
        "    def _update_global_params(self):\n",
        "        self.global_params = OrderedDict()\n",
        "        for name, param in self.global_model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.global_params[name] = param.data.clone()\n",
        "\n",
        "    def client_train(self, client_model, dataloader, epochs=1, lr=1e-4):\n",
        "        if len(dataloader) == 0:\n",
        "            print(\"No data in dataloader, skipping client training\")\n",
        "            return\n",
        "\n",
        "        optimizer = torch.optim.Adam(client_model.parameters(), lr=lr)\n",
        "        client_model.train()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_batches = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(dataloader):\n",
        "                try:\n",
        "                    pixel_values = batch[\"pixel_values\"].cuda()\n",
        "                    input_boxes = batch[\"input_boxes\"].cuda()\n",
        "                    ground_truth_mask = batch[\"ground_truth_mask\"].cuda().float()\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    outputs = client_model(\n",
        "                        pixel_values=pixel_values,\n",
        "                        input_boxes=input_boxes,\n",
        "                        multimask_output=False,\n",
        "                    )\n",
        "\n",
        "                    pred_masks = outputs.pred_masks.squeeze(2)\n",
        "                    gt_masks = ground_truth_mask\n",
        "\n",
        "                    gt_masks_resized = torch.nn.functional.interpolate(\n",
        "                        gt_masks,\n",
        "                        size=pred_masks.shape[-2:],\n",
        "                        mode='bilinear',\n",
        "                        align_corners=False\n",
        "                    )\n",
        "\n",
        "                    loss = nn.BCEWithLogitsLoss()(pred_masks, gt_masks_resized)\n",
        "\n",
        "                    prox_term = 0.0\n",
        "                    for name, param in client_model.named_parameters():\n",
        "                        if param.requires_grad and name in self.global_params:\n",
        "                            prox_term += torch.norm(param - self.global_params[name].cuda()) ** 2\n",
        "\n",
        "                    total_loss_val = loss + (self.mu / 2) * prox_term\n",
        "                    total_loss_val.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "                    total_batches += 1\n",
        "\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ö†Ô∏è Skipping batch {batch_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if total_batches > 0:\n",
        "                avg_loss = total_loss / total_batches\n",
        "                print(f\"Client Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
        "            else:\n",
        "                print(f\"Client Epoch {epoch+1}, No batches processed\")\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
        "    input_boxes = torch.stack([item['input_boxes'] for item in batch])\n",
        "    ground_truth_mask = torch.stack([item['ground_truth_mask'] for item in batch])\n",
        "\n",
        "    return {\n",
        "        'pixel_values': pixel_values,\n",
        "        'input_boxes': input_boxes,\n",
        "        'ground_truth_mask': ground_truth_mask\n",
        "    }\n",
        "\n",
        "def dice_score_np(pred, gt):\n",
        "    \"\"\"Calculate Dice score between prediction and ground truth\"\"\"\n",
        "    intersection = np.logical_and(pred, gt).sum()\n",
        "    total = pred.sum() + gt.sum()\n",
        "    return (2. * intersection) / total if total > 0 else 0.0\n",
        "\n",
        "def meaningful_evaluation(model, dataset, num_samples=10):\n",
        "    \"\"\"Evaluation that shows meaningful results\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    dice_scores = []\n",
        "\n",
        "    print(f\"Evaluating on {min(num_samples, len(dataset))} samples...\")\n",
        "\n",
        "    for i in range(min(num_samples, len(dataset))):\n",
        "        try:\n",
        "            sample = dataset[i]\n",
        "\n",
        "            pixel_values = sample[\"pixel_values\"].unsqueeze(0).cuda()\n",
        "            input_boxes = sample[\"input_boxes\"].unsqueeze(0).cuda()\n",
        "            gt_mask = sample[\"ground_truth_mask\"].squeeze().numpy()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    input_boxes=input_boxes,\n",
        "                    multimask_output=False,\n",
        "                )\n",
        "\n",
        "                pred_mask = torch.sigmoid(outputs.pred_masks.squeeze(2)).squeeze().cpu().numpy()\n",
        "\n",
        "            # Resize ground truth to match prediction\n",
        "            gt_mask_resized = torch.nn.functional.interpolate(\n",
        "                torch.tensor(gt_mask).unsqueeze(0).unsqueeze(0).float(),\n",
        "                size=pred_mask.shape,\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            ).squeeze().numpy()\n",
        "\n",
        "            # Use optimal threshold\n",
        "            pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "            gt_binary = (gt_mask_resized > 0.5).astype(np.uint8)\n",
        "\n",
        "            dice = dice_score_np(pred_binary, gt_binary)\n",
        "            dice_scores.append(dice)\n",
        "\n",
        "            print(f\"Sample {i}: Dice = {dice:.4f}, \"\n",
        "                  f\"GT pixels: {gt_binary.sum()}, \"\n",
        "                  f\"Pred pixels: {pred_binary.sum()}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating sample {i}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Analysis\n",
        "    print(f\"\\nüéØ MEANINGFUL EVALUATION RESULTS:\")\n",
        "    print(f\"   Mean Dice: {np.mean(dice_scores):.4f} (+/- {np.std(dice_scores):.4f})\")\n",
        "    print(f\"   Min Dice: {np.min(dice_scores):.4f}\")\n",
        "    print(f\"   Max Dice: {np.max(dice_scores):.4f}\")\n",
        "    print(f\"   Samples with non-zero GT: {sum(1 for d in dice_scores if d > 0)}/{len(dice_scores)}\")\n",
        "\n",
        "    return dice_scores\n",
        "\n",
        "def federated_learning():\n",
        "    num_clients = 2\n",
        "    num_rounds = 2\n",
        "    epochs_per_client = 1\n",
        "\n",
        "    print(\"Initializing Federated Learning with REAL Brain Tumor Dataset...\")\n",
        "\n",
        "    # Create global model\n",
        "    global_model, processor = create_sam_lora()\n",
        "    global_model = global_model.cuda()\n",
        "\n",
        "    # Initialize FedProx trainer\n",
        "    fed_trainer = FedProxTrainer(global_model, mu=0.01)\n",
        "\n",
        "    for round_idx in range(num_rounds):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"üéØ FEDERATED ROUND {round_idx + 1}/{num_rounds}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        client_models = []\n",
        "        client_dataloaders = []\n",
        "\n",
        "        for client_id in range(num_clients):\n",
        "            print(f\"\\nüì± Initializing Client {client_id}...\")\n",
        "            try:\n",
        "                dataset = RealBrainTumorDataset(path, processor, client_id, num_clients, samples_per_client=20)\n",
        "\n",
        "                if len(dataset) > 0:\n",
        "                    dataloader = DataLoader(\n",
        "                        dataset,\n",
        "                        batch_size=2,\n",
        "                        shuffle=True,\n",
        "                        num_workers=0,\n",
        "                        collate_fn=custom_collate_fn\n",
        "                    )\n",
        "                    client_dataloaders.append(dataloader)\n",
        "\n",
        "                    # load global weights\n",
        "                    client_model, _ = create_sam_lora()\n",
        "                    client_model = client_model.cuda()\n",
        "                    client_model.load_state_dict(global_model.state_dict())\n",
        "                    client_models.append(client_model)\n",
        "                    print(f\"‚úÖ Client {client_id} ready with {len(dataset)} REAL brain tumor samples\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Client {client_id} has no data, skipping\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Client {client_id} failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not client_models:\n",
        "            print(\"‚ùå No clients with data available! Stopping.\")\n",
        "            raise Exception(\"Failed to load real brain tumor data\")\n",
        "\n",
        "        # Client training\n",
        "        print(\"\\n--- üî• CLIENT TRAINING PHASE ---\")\n",
        "        successful_clients = []\n",
        "        for client_id, (client_model, dataloader) in enumerate(zip(client_models, client_dataloaders)):\n",
        "            print(f\"\\nüéØ Training Client {client_id}...\")\n",
        "            try:\n",
        "                fed_trainer.client_train(client_model, dataloader, epochs_per_client)\n",
        "                successful_clients.append(client_model)\n",
        "                print(f\"‚úÖ Client {client_id} training completed\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Client {client_id} training failed: {e}\")\n",
        "\n",
        "        # LoRA aggregation\n",
        "        print(\"\\n--- üîÑ MODEL AGGREGATION PHASE ---\")\n",
        "        if successful_clients:\n",
        "            global_dict = global_model.state_dict()\n",
        "            aggregated_params = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for key in global_dict:\n",
        "                    if 'lora' in key.lower():\n",
        "                        client_params = []\n",
        "                        for client_model in successful_clients:\n",
        "                            client_dict = client_model.state_dict()\n",
        "                            if key in client_dict:\n",
        "                                client_params.append(client_dict[key])\n",
        "\n",
        "                        if client_params:\n",
        "                            global_dict[key] = torch.stack(client_params).mean(dim=0)\n",
        "                            aggregated_params += 1\n",
        "\n",
        "            global_model.load_state_dict(global_dict)\n",
        "            fed_trainer._update_global_params()\n",
        "            print(f\"‚úÖ Aggregated {aggregated_params} LoRA parameters from {len(successful_clients)} clients\")\n",
        "        else:\n",
        "            print(\"‚ùå No clients to aggregate from!\")\n",
        "\n",
        "        # Evaluation\n",
        "        print(\"\\n--- üìä EVALUATION PHASE ---\")\n",
        "        if client_dataloaders and len(client_dataloaders[0].dataset) > 0:\n",
        "            meaningful_evaluation(global_model, client_dataloaders[0].dataset, num_samples=10)\n",
        "\n",
        "    print(\"\\nüéâ FEDERATED LEARNING COMPLETED!\")\n",
        "    return global_model, processor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Starting Federated SAM with LoRA on REAL Brain Tumor Dataset\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    test_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
        "    try:\n",
        "        test_dataset = RealBrainTumorDataset(path, test_processor, client_id=0, num_clients=1, samples_per_client=5)\n",
        "\n",
        "        if len(test_dataset) > 0:\n",
        "            print(f\"‚úÖ REAL brain tumor dataset loaded: {len(test_dataset)} samples\")\n",
        "\n",
        "            # Start federated learning\n",
        "            trained_model, trained_processor = federated_learning()\n",
        "\n",
        "            # Final evaluation\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"FINAL EVALUATION\")\n",
        "            print(\"=\"*60)\n",
        "            final_dataset = RealBrainTumorDataset(path, trained_processor, client_id=0, num_clients=1, samples_per_client=20)\n",
        "            meaningful_evaluation(trained_model, final_dataset, num_samples=10)\n",
        "        else:\n",
        "            print(\" No real data loaded\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load real dataset: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a01gK6aBlxdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def comprehensive_visualization(model, dataset, num_samples=8):\n",
        "    \"\"\"COMPREHENSIVE visualization of images, ground truth, and predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"üéØ VISUALIZING PREDICTIONS (Dice: 0.87)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create larger grid\n",
        "    fig, axes = plt.subplots(num_samples, 5, figsize=(25, 5*num_samples))\n",
        "\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    all_dice_scores = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        try:\n",
        "            # Get sample\n",
        "            sample = dataset[i]\n",
        "            image_path = dataset.images[i]\n",
        "            mask_path = dataset.masks[i]\n",
        "\n",
        "            # Load original files\n",
        "            original_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "            original_mask = np.array(Image.open(mask_path))\n",
        "\n",
        "            # CORRECT binarization\n",
        "            gt_binary = (original_mask == 255).astype(np.uint8)\n",
        "\n",
        "            # Get prediction\n",
        "            pixel_values = sample[\"pixel_values\"].unsqueeze(0).cuda()\n",
        "            input_boxes = sample[\"input_boxes\"].unsqueeze(0).cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    input_boxes=input_boxes,\n",
        "                    multimask_output=False,\n",
        "                )\n",
        "\n",
        "                pred_mask = torch.sigmoid(outputs.pred_masks.squeeze(2)).squeeze().cpu().numpy()\n",
        "\n",
        "            # Resize prediction\n",
        "            pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "            pred_binary_resized = np.array(Image.fromarray(pred_binary).resize((512, 512), Image.NEAREST))\n",
        "\n",
        "            # Calculate metrics\n",
        "            intersection = np.logical_and(pred_binary_resized, gt_binary).sum()\n",
        "            union = np.logical_or(pred_binary_resized, gt_binary).sum()\n",
        "            dice = (2. * intersection) / (pred_binary_resized.sum() + gt_binary.sum())\n",
        "            iou = intersection / union if union > 0 else 0\n",
        "\n",
        "            all_dice_scores.append(dice)\n",
        "\n",
        "            # ========== PLOTTING ==========\n",
        "\n",
        "            # 1. Original Image\n",
        "            axes[i, 0].imshow(original_image)\n",
        "            axes[i, 0].set_title(f\"Input Image\\n{os.path.basename(image_path)}\", fontsize=14, weight='bold')\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            # 2. Original Mask (raw)\n",
        "            axes[i, 1].imshow(original_mask, cmap='gray')\n",
        "            axes[i, 1].set_title(f\"Original Mask\\nValues: {np.unique(original_mask)}\", fontsize=14)\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            # 3. Ground Truth Binary\n",
        "            axes[i, 2].imshow(gt_binary, cmap='viridis')\n",
        "            axes[i, 2].set_title(f\"Ground Truth Binary\\nPixels: {gt_binary.sum()}\", fontsize=14, weight='bold')\n",
        "            axes[i, 2].axis('off')\n",
        "\n",
        "            # 4. Prediction\n",
        "            axes[i, 3].imshow(pred_binary_resized, cmap='viridis')\n",
        "            axes[i, 3].set_title(f\"Prediction\\nPixels: {pred_binary_resized.sum()}\", fontsize=14, weight='bold')\n",
        "            axes[i, 3].axis('off')\n",
        "\n",
        "            # 5. Overlay Comparison\n",
        "            overlay = original_image.copy()\n",
        "            # Green for correct predictions (True Positives)\n",
        "            overlay[np.logical_and(pred_binary_resized == 1, gt_binary == 1)] = [0, 255, 0]\n",
        "            # Red for false positives\n",
        "            overlay[np.logical_and(pred_binary_resized == 1, gt_binary == 0)] = [255, 0, 0]\n",
        "            # Blue for false negatives\n",
        "            overlay[np.logical_and(pred_binary_resized == 0, gt_binary == 1)] = [0, 0, 255]\n",
        "\n",
        "            axes[i, 4].imshow(overlay)\n",
        "            axes[i, 4].set_title(f\"Overlay\\nDice: {dice:.3f}, IoU: {iou:.3f}\", fontsize=14, weight='bold')\n",
        "            axes[i, 4].axis('off')\n",
        "\n",
        "            print(f\"‚úÖ Sample {i}: Dice = {dice:.4f}, IoU = {iou:.4f}\")\n",
        "            print(f\"   GT: {gt_binary.sum()} pixels, Pred: {pred_binary_resized.sum()} pixels\")\n",
        "            print(f\"   File: {os.path.basename(image_path)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in sample {i}: {e}\")\n",
        "            continue\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nüìä SUMMARY: Average Dice = {np.mean(all_dice_scores):.4f} ¬± {np.std(all_dice_scores):.4f}\")\n",
        "    return all_dice_scores\n",
        "\n",
        "def detailed_sample_analysis(model, dataset, sample_indices=[0, 1, 2]):\n",
        "    \"\"\"DETAILED analysis of specific samples\"\"\"\n",
        "    print(\"üî¨ DETAILED SAMPLE ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for idx in sample_indices:\n",
        "        try:\n",
        "            sample = dataset[idx]\n",
        "            image_path = dataset.images[idx]\n",
        "            mask_path = dataset.masks[idx]\n",
        "\n",
        "            # Load data\n",
        "            original_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "            original_mask = np.array(Image.open(mask_path))\n",
        "            gt_binary = (original_mask == 255).astype(np.uint8)\n",
        "\n",
        "            # Get prediction\n",
        "            pixel_values = sample[\"pixel_values\"].unsqueeze(0).cuda()\n",
        "            input_boxes = sample[\"input_boxes\"].unsqueeze(0).cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    input_boxes=input_boxes,\n",
        "                    multimask_output=False,\n",
        "                )\n",
        "\n",
        "                pred_mask = torch.sigmoid(outputs.pred_masks.squeeze(2)).squeeze().cpu().numpy()\n",
        "\n",
        "            pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "            pred_binary_resized = np.array(Image.fromarray(pred_binary).resize((512, 512), Image.NEAREST))\n",
        "\n",
        "            # Calculate detailed metrics\n",
        "            intersection = np.logical_and(pred_binary_resized, gt_binary).sum()\n",
        "            union = np.logical_or(pred_binary_resized, gt_binary).sum()\n",
        "            fp = np.logical_and(pred_binary_resized == 1, gt_binary == 0).sum()\n",
        "            fn = np.logical_and(pred_binary_resized == 0, gt_binary == 1).sum()\n",
        "            tp = intersection\n",
        "            tn = np.logical_and(pred_binary_resized == 0, gt_binary == 0).sum()\n",
        "\n",
        "            dice = (2. * tp) / (pred_binary_resized.sum() + gt_binary.sum())\n",
        "            iou = tp / union if union > 0 else 0\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "            print(f\"\\nüìã SAMPLE {idx}: {os.path.basename(image_path)}\")\n",
        "            print(f\"   Original mask values: {np.unique(original_mask)}\")\n",
        "            print(f\"   GT binary pixels: {gt_binary.sum()}\")\n",
        "            print(f\"   Predicted pixels: {pred_binary_resized.sum()}\")\n",
        "            print(f\"   True Positives:  {tp}\")\n",
        "            print(f\"   False Positives: {fp}\")\n",
        "            print(f\"   False Negatives: {fn}\")\n",
        "            print(f\"   Dice: {dice:.4f}, IoU: {iou:.4f}\")\n",
        "            print(f\"   Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "            # Create detailed visualization for this sample\n",
        "            fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "            # Row 1\n",
        "            axes[0,0].imshow(original_image)\n",
        "            axes[0,0].set_title(\"Original Image\")\n",
        "            axes[0,0].axis('off')\n",
        "\n",
        "            axes[0,1].imshow(original_mask, cmap='gray')\n",
        "            axes[0,1].set_title(\"Original Mask\")\n",
        "            axes[0,1].axis('off')\n",
        "\n",
        "            axes[0,2].imshow(gt_binary, cmap='viridis')\n",
        "            axes[0,2].set_title(f\"GT Binary\\n{gt_binary.sum()} pixels\")\n",
        "            axes[0,2].axis('off')\n",
        "\n",
        "            axes[0,3].imshow(pred_binary_resized, cmap='viridis')\n",
        "            axes[0,3].set_title(f\"Prediction\\n{pred_binary_resized.sum()} pixels\")\n",
        "            axes[0,3].axis('off')\n",
        "\n",
        "            # Row 2 - Detailed overlays\n",
        "            # TP/FP/FN overlay\n",
        "            overlay_detailed = np.zeros_like(original_image)\n",
        "            overlay_detailed[tp > 0] = [0, 255, 0]    # Green = TP\n",
        "            overlay_detailed[fp > 0] = [255, 0, 0]    # Red = FP\n",
        "            overlay_detailed[fn > 0] = [0, 0, 255]    # Blue = FN\n",
        "\n",
        "            axes[1,0].imshow(overlay_detailed)\n",
        "            axes[1,0].set_title(\"TP/FP/FN Map\\nGreen=TP, Red=FP, Blue=FN\")\n",
        "            axes[1,0].axis('off')\n",
        "\n",
        "            # Overlay on original\n",
        "            overlay_original = original_image.copy()\n",
        "            overlay_original[tp > 0] = [0, 255, 0]    # Green = TP\n",
        "            overlay_original[fp > 0] = [255, 0, 0]    # Red = FP\n",
        "            overlay_original[fn > 0] = [0, 0, 255]    # Blue = FN\n",
        "\n",
        "            axes[1,1].imshow(overlay_original)\n",
        "            axes[1,1].set_title(\"Overlay on Image\")\n",
        "            axes[1,1].axis('off')\n",
        "\n",
        "            # Prediction confidence\n",
        "            pred_resized = np.array(Image.fromarray(pred_mask).resize((512, 512), Image.BILINEAR))\n",
        "            im = axes[1,2].imshow(pred_resized, cmap='hot')\n",
        "            axes[1,2].set_title(\"Prediction Confidence\")\n",
        "            axes[1,2].axis('off')\n",
        "            plt.colorbar(im, ax=axes[1,2])\n",
        "\n",
        "            # Metrics text\n",
        "            axes[1,3].text(0.1, 0.9, f\"Dice: {dice:.4f}\", fontsize=16, weight='bold')\n",
        "            axes[1,3].text(0.1, 0.7, f\"IoU: {iou:.4f}\", fontsize=16, weight='bold')\n",
        "            axes[1,3].text(0.1, 0.5, f\"Precision: {precision:.4f}\", fontsize=16)\n",
        "            axes[1,3].text(0.1, 0.3, f\"Recall: {recall:.4f}\", fontsize=16)\n",
        "            axes[1,3].text(0.1, 0.1, f\"File: {os.path.basename(image_path)}\", fontsize=12)\n",
        "            axes[1,3].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in detailed analysis {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "def check_different_tumor_types(model, dataset, num_samples_per_type=3):\n",
        "    \"\"\"Check performance across different tumor types\"\"\"\n",
        "    print(\"üß† TUMOR TYPE PERFORMANCE CHECK\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    tumor_types = {}\n",
        "\n",
        "    for i in range(min(20, len(dataset))):\n",
        "        try:\n",
        "            image_path = dataset.images[i]\n",
        "\n",
        "            # Determine tumor type from filename\n",
        "            if \"Pituitary\" in image_path:\n",
        "                tumor_type = \"Pituitary\"\n",
        "            elif \"Meningioma\" in image_path:\n",
        "                tumor_type = \"Meningioma\"\n",
        "            elif \"Glioma\" in image_path:\n",
        "                tumor_type = \"Glioma\"\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if tumor_type not in tumor_types:\n",
        "                tumor_types[tumor_type] = []\n",
        "\n",
        "            if len(tumor_types[tumor_type]) >= num_samples_per_type:\n",
        "                continue\n",
        "\n",
        "            # Calculate Dice for this sample\n",
        "            sample = dataset[i]\n",
        "            mask_path = dataset.masks[i]\n",
        "\n",
        "            original_mask = np.array(Image.open(mask_path))\n",
        "            gt_binary = (original_mask == 255).astype(np.uint8)\n",
        "\n",
        "            pixel_values = sample[\"pixel_values\"].unsqueeze(0).cuda()\n",
        "            input_boxes = sample[\"input_boxes\"].unsqueeze(0).cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    input_boxes=input_boxes,\n",
        "                    multimask_output=False,\n",
        "                )\n",
        "\n",
        "                pred_mask = torch.sigmoid(outputs.pred_masks.squeeze(2)).squeeze().cpu().numpy()\n",
        "\n",
        "            pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "            pred_binary_resized = np.array(Image.fromarray(pred_binary).resize((512, 512), Image.NEAREST))\n",
        "\n",
        "            dice = dice_score_np(pred_binary_resized, gt_binary)\n",
        "            tumor_types[tumor_type].append(dice)\n",
        "\n",
        "            print(f\"‚úÖ {tumor_type}: Sample {len(tumor_types[tumor_type])} - Dice: {dice:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\nüìä TUMOR TYPE SUMMARY:\")\n",
        "    for tumor_type, scores in tumor_types.items():\n",
        "        if scores:\n",
        "            print(f\"   {tumor_type}: {np.mean(scores):.4f} ¬± {np.std(scores):.4f} (n={len(scores)})\")\n",
        "\n",
        "def dice_score_np(pred, target):\n",
        "    \"\"\"Dice score calculation\"\"\"\n",
        "    intersection = np.logical_and(pred, target).sum()\n",
        "    return (2. * intersection) / (pred.sum() + target.sum()) if (pred.sum() + target.sum()) > 0 else 0\n",
        "\n",
        "# üöÄ RUN THE COMPREHENSIVE ANALYSIS\n",
        "print(\"üéØ RUNNING COMPREHENSIVE ANALYSIS FOR 0.87 DICE MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Main visualization\n",
        "print(\"\\n1. üìä COMPREHENSIVE VISUALIZATION\")\n",
        "dice_scores = comprehensive_visualization(trained_model, final_dataset, num_samples=6)\n",
        "\n",
        "# 2. Detailed analysis of first few samples\n",
        "print(\"\\n2. üî¨ DETAILED SAMPLE ANALYSIS\")\n",
        "detailed_sample_analysis(trained_model, final_dataset, sample_indices=[0, 1, 2, 3])\n",
        "\n",
        "# 3. Check different tumor types\n",
        "print(\"\\n3. üß† TUMOR TYPE PERFORMANCE\")\n",
        "check_different_tumor_types(trained_model, final_dataset)\n",
        "\n",
        "print(f\"\\nüéâ THE MODEL IS PERFORMING Well!\")\n",
        "print(f\"   Average Dice: {np.mean(dice_scores):.4f}\")\n",
        "print(f\"\")"
      ],
      "metadata": {
        "id": "wqYYIFf0V3-T"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}